\chapter{Implementation}

\section{Introduction}

\subsection{Tools}

As part of this thesis two tools have been developed to gather information about an application:

\texttt{pintool\_static.so} analyses the application and all its shared libraries and creates a database with all the locations in the source code where a tag can be placed. More details are present in Section \ref{cap3:pintoolstatic}.

\texttt{pintool\_dynamic.so} is an Intel Pin tool that performs tracing of the target application. It uses the database created by \texttt{pintool\_static.so} and adds all the gathered information. The tool is extensively explained in Section \ref{cap3:pintooldynamic}.

\subsection{Analysis}


\subsection{Visualizations}

The database created by \texttt{pintool\_dynamic.so} is compatible with the format used by Parceive, but it adds some additional data. Existing views continue to work and have been extended to display this additional information.

\subsection{Workflow}

\begin{figure}
	\centering
	\includegraphics[width=1\textwidth]{workflow}
	\caption{User workflow}
	\label{cap3:workflow}
\end{figure}

Figure \ref{cap3:workflow} shows the workflow when using our tools.  Because we are using dynamic binary instrumentation a user must first build the application executable. The static analysis needs to be executed every time the program is modified and rebuilt.

The dynamic analysis can be executed multiple times to gather more information. First the user tags sections of the source code and runs the analysis. The visualizations provide useful information about the executed program and the user can choose to perform another analysis if more data is required.

\subsection{Architecture}

Figure \ref{architecture} shows the architecture of the entire project. It is similar to the one used by Parceive as shown in Figure \ref{parceive:architecture}.

\begin{figure}
	\centering
	\includegraphics[width=1\textwidth]{architecture}
	\caption{System architecture}
	\label{architecture}
\end{figure}

The split between the dynamic and static analysis was needed because the user must be able to tag the source code of the application before tracing is performed. The database processing, the Node.js server and the ORM have been extended to support our use cases.

\section{Concepts}

\subsection{Filtering}

By using dynamic binary instrumentation it is possible to process the entire instruction stream of an application, even dynamic libraries and setup code generated by the compiler. Recording all the actions an application performs might be an advantage, but comes at the cost of runtime overhead and a large tracing database. If a developer is not interested in analyzing the entire application the overhead and the size can be reduced by defining parts that should be ignored.

In Parceive and our implementations three types of filters are available:

\textbf{Image} represents the executable or a shared library and can be used to easily ignore code that is not being developed.

\textbf{Function} represents a routine in the executable. This can be used to filter out modules from inside the executable or shared libraries based on the naming convention of the project.

\textbf{File} allows a developer to filter functions based on the file they were defined in. This requires debug for the component that contains the function. This is also the easiest way to only consider code that has debug information.

\subsection{Tags}

Tags are used to mark interesting parts of the code and to provide input to automatic program analyses. Multiple tag types are available:

\begin{itemize}
	\item [Section] marks the boundaries of a section of code that can be executed in parallel.
	\item [SectionTask] is a task inside a section. Each task can be run in parallel to any other task. When a new task is started, the old one is ended automatically.
	\item [Pipeline] marks the boundaries of a section of code that can be executed in parallel using a pipeline architecture.
	\item [PipelineIteration] represents one iteration of the pipeline.
	\item [PipelineSection] is a section of a iteration. These sections can be run in parallel to different sections from different iterations.
\end{itemize}

\subsubsection{Controling tracing}
Filtering can reduce the amount of data gathered during a programs execution, but tags can provide an even more flexible approach. Using tags it is possible to control tracing during execution with the granularity of a line:

\begin{itemize}
	\item [IgnoreAll] stops all tracing.
	\item [IgnoreCalls] stops the tracing of calls.
	\item [IgnoreAccesses] stops the tracing of accesses.
	\item [ProcessAll] forces the tracing of everything.
	\item [ProcessCalls] forces the tracing of calls.
	\item [ProcessAccesses] starts the tracing of accesses.
\end{itemize}

In Figure \ref{cap3:contralg} we can see the algorithm used to determine whether tracing is performed.

\begin{figure}
	\begin{center}
		\begin{minted}{c}
			if (ignoreCalls)
				processCallsComputed = false;
			else if (processCalls)
				processCallsComputed = true;
			else if (interestingProgramPart)
				processCallsComputed = true;
			else
				processCallsComputed = true;
			
			if (!processCallsComputed)
				processAccessesComputed = false;
			else if (ignoreAccesses)
				processAccessesComputed = false;
			else if (processAccesses)
				processAccessesComputed = true;
			else if (interestingProgramPart)
				processAccessesComputed = true;
			else
				processAccessesComputed = false;
		\end{minted}
	\end{center}
	\caption{Algorithm to determine if tracing is performed}
	\label{cap3:contralg}
\end{figure}

\section{Database layout}

Additional tables have been added to the parceive database to store information about tags and the layout of the source code. The \texttt{SourceLocation} table contains all locations in the code that are referenced in the debug information and can be used for tags.

\section{pintool\_static.so}
\label{cap3:pintoolstatic}

\texttt{pintool\_static.so} performs static analysis on the executable and all the loaded dynamic libraries to determine the relationship between the source code and the executable. The instrumented application is executed to discover the dynamic libraries loaded at runtime.

\subsubsection{Source Locations}

Performing the analysis generates a database of all locations where a tag can be inserted into the application source code. This information is important because it is not obvious which line of code results in executable instructions, especially at block boundaries.

\subsubsection{File View}

The File View can render the files that were used to build the instrumented application.

\subsubsection{Tagging}

The File View can tag sections of the source code to generate an input for the dynamic analysis. 

\section{pintool\_dynamic.so}
\label{cap3:pintooldynamic}

\texttt{pintool\_static.so} performs a dynamic analysis on the application.

\subsubsection{Architecture}



\subsubsection{Fast buffer API}
\subsubsection{Allocation interception}
\subsubsection{Shadow Stack}
\subsubsection{Tagging implementation}
\subsubsection{Memory accesses}
\subsubsection{Reference resolution}
\subsubsection{Thread handling}
\subsubsection{Tag handling}

\section{Analysis}

\subsection{Section}
\subsubsection{Introduction}
\subsubsection{Parallelization}
\subsubsection{Dependency detection}
\subsubsection{Visualization}

\subsection{Pipeline}
\subsubsection{Introduction}
\subsubsection{Parallelization}
\subsubsection{Dependency detection}
\subsubsection{Visualization}

\subsection{Calling Context Tree}
\subsubsection{Parceive UI}
\subsubsection{Modifications}

\section{Visualizations}

Additional visualizations have been implemented to enable source code tagging and to display the information obtained by the analysis:

\textbf{File View}

\textbf{Tag List}

\textbf{Section View}

\textbf{Pipeline View}

Additionally existing views have been extended to provide more information about tags:

\textbf{Detail View}

\textbf{CCT View}






